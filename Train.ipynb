{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebdb480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, sys, h5py, time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "#dedicate packages import\n",
    "sys.path.append(r'C:\\Users\\hvanvoorst\\PhD\\git_repos\\FU2BL-GAN')\n",
    "from options.options_FU2BL import get_options\n",
    "from utils.TrainUtils import get_scheduler\n",
    "from scripts.Train_FU2BL import FU2BL_GAN\n",
    "from scripts.init_train import init_loader\n",
    "#from utils.Augment import * # import all augmentation functions\n",
    "from utils.Utils import *\n",
    "\n",
    "opt = get_options()\n",
    "# set path to location to store checkpoints and h5py file for loading data\n",
    "opt.loc_checkpoints = r''\n",
    "opt.train_filepath = r''\n",
    "print(opt.train_filepath, opt.input_n_slices, opt.cache_size, opt.loc_checkpoints)\n",
    "\n",
    "#import the loader for training\n",
    "train_ldr, train_dataset, TSS = init_loader(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model class (includes Discriminator and Generator models)\n",
    "model = FU2BL_GAN(opt)\n",
    "print(model.loc_checkpoints)\n",
    "\n",
    "if not os.path.exists(model.loc_checkpoints):\n",
    "    os.makedirs(model.loc_checkpoints)\n",
    "\n",
    "eps = opt.n_epochs_same+opt.n_epochs_decay+2\n",
    "print('Start training at:', datetime.now(), \n",
    "      '\\nStarting with epoch number:', model.epoch, \n",
    "      '\\nTraining for', eps, 'epochs')\n",
    "\n",
    "# initialize start epoch and lr scheduling \n",
    "opt.epoch_count = model.epoch\n",
    "scheduler_D = get_scheduler(model.optimizer_D,opt)\n",
    "scheduler_G = get_scheduler(model.optimizer_G,opt)\n",
    "\n",
    "total_iters = model.iter\n",
    "train_G, train_D = True, True #allows for alternated training (more D than G for example)\n",
    "for epoch in range(model.epoch,eps):\n",
    "    epoch_start = time.time()\n",
    "    for i,(BL,FU,ID) in enumerate(train_ldr): \n",
    "        t1 = time.time()\n",
    "        total_iters += BL.shape[0]\n",
    "\n",
    "        model.set_input(FU, BL) \n",
    "        model.optimize_parameters()\n",
    "\n",
    "        t2 = time.time()\n",
    "        t = round(t2-t1)\n",
    "        model.at_iter_end(epoch,total_iters,ID, train_G,train_D,t, \n",
    "                          save=True, val_loader=None, # set val_loader to None if no validation set\n",
    "                          epoch_end=(i==len(train_ldr)-1))\n",
    "\n",
    "\n",
    "    print('Epoch:',epoch,'--iteration:', i, \n",
    "          '--total-n-slices:',total_iters,\n",
    "          train_G, train_D,#multistop_D,\n",
    "          'G-loss:', round(model.loss_G.item(),3), \n",
    "          'D-loss:',round(model.loss_D.item(),3),'\\n',\n",
    "          'Fake acc:', round(model.acc_fake,2),\n",
    "          'Real acc:', round(model.acc_real,2),\n",
    "          t,len(model.errors))\n",
    "\n",
    "    scheduler_D.step()\n",
    "    scheduler_G.step()\n",
    "\n",
    "    epoch_end = time.time()\n",
    "\n",
    "    print('finished epoch:', epoch, 'in:', round(epoch_end-epoch_start), 'seconds')\n",
    "print('Finished training:',datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e19ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
